{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term-Frequency Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Vectorizers and model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5728 entries, 0 to 5727\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    5728 non-null   object\n",
      " 1   spam    5728 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 89.6+ KB\n",
      "None\n",
      "\n",
      " spam\n",
      "0    4360\n",
      "1    1368\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data from https://www.kaggle.com/datasets/jackksoncsie/spam-email-dataset?resource=download\n",
    "data = pd.read_csv('../data/external/emails.csv')\n",
    "print(data.info())\n",
    "print('\\n',data.spam.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naturally irresistible corporate identity lt really hard recollect company market full suqgestions information isoverwhelminq good catchy logo stylish statlonery outstanding website make task much easier do not promise havinq ordered iogo company automaticaily become world ieader isguite ciear without good products effective business organization practicable aim hotat nowadays market do promise marketing efforts become much more effective here list clear benefits creativeness hand made original logos specially done reflect distinctive company image convenience logo stationery provided all formats easy use content management system letsyou change website content even its structure promptness see logo drafts within three business days affordability marketing break through shouldn t make gaps budget satisfaction guaranteed provide unlimited amount changes with no extra fees for surethat love result this collaboration have look at portfolio not interested\n"
     ]
    }
   ],
   "source": [
    "# Get sample\n",
    "sample = data.iloc[0,0]\n",
    "\n",
    "# Instantiate stops words\n",
    "stop_words = ['a', 'an', 'and', 'are', 'be', 'but', 'from', 'if', 'in', 'is', 'it', 'of', 'on', 'our', 'that', 'the', 'to', 'we', 'will', 'you', 'your']\n",
    "\n",
    "# Clean in order\n",
    "def clean_text(text, print_result=False, stop_words=stop_words):\n",
    "    # Instantiate patterns for cleaning\n",
    "    patt_remove_subj = r'(?i)subject:\\s?' # Drop opening \"subject:' mention\n",
    "    patt_remove_non_alpha = r'[^a-zA-Z\\s]' # Remove anything that is not a word or space character\n",
    "    patt_remove_new_lines_and_multiple_spaces = r'[^\\w\\s]' # Remove anything that is not a word or space character\n",
    "    \n",
    "    # Apply cleaning steps\n",
    "    for patt in [patt_remove_subj, patt_remove_non_alpha, patt_remove_new_lines_and_multiple_spaces]:\n",
    "        text = re.sub(patt,'',text)\n",
    "    \n",
    "    # Drop stopwords\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "\n",
    "    # See clean sample\n",
    "    if print_result:\n",
    "        print(text)\n",
    "        return text\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# See example\n",
    "clean_sample = clean_text(sample, print_result=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "      <td>naturally irresistible corporate identity lt r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "      <td>stock trading gunslinger fanny merrill muzo no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "      <td>unbelievable new homes made easy im wanting sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "      <td>color printing special request additional info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "      <td>do not have money get software cds here softwa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam  \\\n",
       "0  Subject: naturally irresistible your corporate...     1   \n",
       "1  Subject: the stock trading gunslinger  fanny i...     1   \n",
       "2  Subject: unbelievable new homes made easy  im ...     1   \n",
       "3  Subject: 4 color printing special  request add...     1   \n",
       "4  Subject: do not have money , get software cds ...     1   \n",
       "\n",
       "                                          clean_text  \n",
       "0  naturally irresistible corporate identity lt r...  \n",
       "1  stock trading gunslinger fanny merrill muzo no...  \n",
       "2  unbelievable new homes made easy im wanting sh...  \n",
       "3  color printing special request additional info...  \n",
       "4  do not have money get software cds here softwa...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement cleaning to all text\n",
    "data['clean_text'] = data['text'].apply(clean_text)\n",
    "data.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Inverse Document Frequency (IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of unique terms: 33,720\n",
      "5728\n"
     ]
    }
   ],
   "source": [
    "# Get list of documents\n",
    "clean_text_list = data.clean_text.to_list()\n",
    "documents_list = [doc.split() for doc in clean_text_list]\n",
    "\n",
    "# Get all text as a single string\n",
    "documents_str = ' '.join(doc for doc in clean_text_list)\n",
    "\n",
    "# Get unique words and see count\n",
    "unique_term_list = list(set(documents_str.split()))\n",
    "\n",
    "print(f'Length of unique terms: {len(unique_term_list):,}')\n",
    "print(len(documents_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idf(term):\n",
    "\n",
    "    # Calcuate inverse document frequency\n",
    "    num_docs_containing_word = sum(1 for doc in documents_list if term in doc)\n",
    "    N = len(documents_list)\n",
    "    idf = np.log(N / (1 + num_docs_containing_word)) \n",
    "    return idf\n",
    "\n",
    "# Get dataframe\n",
    "idf_df = pd.DataFrame(data=unique_term_list, columns=['term'])\n",
    "\n",
    "# Create IDF values\n",
    "idf_df['idf'] = idf_df['term'].apply(get_idf)\n",
    "\n",
    "# Create vocab ID column and set term as index\n",
    "idf_df.reset_index(drop=False, names = 'vocab_id', inplace=True)\n",
    "idf_df.set_index('term',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab_id</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>principie</th>\n",
       "      <td>0</td>\n",
       "      <td>7.959975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>halluin</th>\n",
       "      <td>1</td>\n",
       "      <td>7.266827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estranged</th>\n",
       "      <td>2</td>\n",
       "      <td>7.554509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fritch</th>\n",
       "      <td>3</td>\n",
       "      <td>7.959975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>southtrust</th>\n",
       "      <td>4</td>\n",
       "      <td>7.959975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            vocab_id       idf\n",
       "term                          \n",
       "principie          0  7.959975\n",
       "halluin            1  7.266827\n",
       "estranged          2  7.554509\n",
       "fritch             3  7.959975\n",
       "southtrust         4  7.959975"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_frequency(document):\n",
    "    \n",
    "    # Get length of row\n",
    "    term_list = document.split()\n",
    "    num_of_terms = len(term_list)\n",
    "    \n",
    "    # Get term frequency for each row\n",
    "    counter_dct = Counter(term_list)\n",
    "\n",
    "    # Convert counter object to dictionary, then dataframe\n",
    "    tf_dct = {key:(counter_dct[key]/num_of_terms) for key in counter_dct if counter_dct[key] > 0}\n",
    "\n",
    "    return tf_dct\n",
    "\n",
    "data['tf'] = data['clean_text'].apply(get_term_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_idf(tf_dict):\n",
    "\n",
    "    \"\"\"\n",
    "    For each document in dataframe, calculate the term-frequency (TF).\n",
    "    Next, search the IDF dataframe for the corresponding IDF value and vocab ID for each term.\n",
    "    Finally, take the product of the TF and IDF and add to TF-IDF dictionary with vocab ID as key.\n",
    "    \"\"\"\n",
    "\n",
    "    tf_idf_dct = {}\n",
    "\n",
    "    # Loop through dictionary representing each document (row)\n",
    "    for term in tf_dict:\n",
    "\n",
    "        # Get term frequency from dictionary\n",
    "        tf = tf_dict[term]\n",
    "\n",
    "        # Get the corresponding idf value for the given term\n",
    "        idf = idf_df.loc[term,'idf']\n",
    "\n",
    "        # Get the corresponding idf value for the given term\n",
    "        vocab_id = idf_df.loc[term,'vocab_id']\n",
    "        \n",
    "        # Multiply tf by idf for tf-idf\n",
    "        tf_idf = tf * idf\n",
    "\n",
    "        # Create dictionary item using vocab_id and tf-idf\n",
    "        tf_idf_dct[vocab_id] = tf_idf\n",
    "    \n",
    "    return tf_idf_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tf_idf columns\n",
    "data['tf_idf'] = data['tf'].apply(get_tf_idf)\n",
    "\n",
    "# Narrow dataframe to key columns\n",
    "df = data[['clean_text','tf_idf','spam']].copy()\n",
    "\n",
    "# Rename label column\n",
    "df.rename(columns={'spam':'label'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tf_idf</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naturally irresistible corporate identity lt r...</td>\n",
       "      <td>{23737: 0.04558552702636202, 29850: 0.05460219...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stock trading gunslinger fanny merrill muzo no...</td>\n",
       "      <td>{23317: 0.05089119735585338, 11618: 0.03300236...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unbelievable new homes made easy im wanting sh...</td>\n",
       "      <td>{7489: 0.13415673810123765, 4050: 0.0331978551...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>color printing special request additional info...</td>\n",
       "      <td>{10839: 0.09809136673852725, 5630: 0.196182733...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>do not have money get software cds here softwa...</td>\n",
       "      <td>{12109: 0.04026561719433407, 9254: 0.031192238...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  \\\n",
       "0  naturally irresistible corporate identity lt r...   \n",
       "1  stock trading gunslinger fanny merrill muzo no...   \n",
       "2  unbelievable new homes made easy im wanting sh...   \n",
       "3  color printing special request additional info...   \n",
       "4  do not have money get software cds here softwa...   \n",
       "\n",
       "                                              tf_idf  label  \n",
       "0  {23737: 0.04558552702636202, 29850: 0.05460219...      1  \n",
       "1  {23317: 0.05089119735585338, 11618: 0.03300236...      1  \n",
       "2  {7489: 0.13415673810123765, 4050: 0.0331978551...      1  \n",
       "3  {10839: 0.09809136673852725, 5630: 0.196182733...      1  \n",
       "4  {12109: 0.04026561719433407, 9254: 0.031192238...      1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See results\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF from Scratch and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8726003490401396\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       856\n",
      "           1       1.00      0.50      0.66       290\n",
      "\n",
      "    accuracy                           0.87      1146\n",
      "   macro avg       0.93      0.75      0.79      1146\n",
      "weighted avg       0.89      0.87      0.86      1146\n",
      "\n",
      "Confusion Matrix:\n",
      " [[856   0]\n",
      " [146 144]]\n"
     ]
    }
   ],
   "source": [
    "# Convert tf_idf column to list of dictionaries\n",
    "X = df['tf_idf'].values.tolist()  \n",
    "y = df['label'].values\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert TF-IDF dictionaries into lists of values\n",
    "vectorizer = DictVectorizer(sparse=True)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize and train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = model.score(X_test_vec, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF and Logistic Regression with Sci-Kit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9773123909249564\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       856\n",
      "           1       1.00      0.91      0.95       290\n",
      "\n",
      "    accuracy                           0.98      1146\n",
      "   macro avg       0.98      0.96      0.97      1146\n",
      "weighted avg       0.98      0.98      0.98      1146\n",
      "\n",
      "Confusion Matrix:\n",
      " [[855   1]\n",
      " [ 25 265]]\n"
     ]
    }
   ],
   "source": [
    "# Convert tf_idf column to list of dictionaries\n",
    "X1 = df['clean_text'].values.tolist()  \n",
    "y1 = df['label'].values\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform\n",
    "X_train_vec_sklearn = vectorizer.fit_transform(X_train1)\n",
    "X_test_vec_sklearn = vectorizer.transform(X_test1)\n",
    "\n",
    "# Initialize and train logistic regression model\n",
    "model_sklearn = LogisticRegression()\n",
    "model_sklearn.fit(X_train_vec_sklearn, y_train1)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred1 = model_sklearn.predict(X_test_vec_sklearn)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy1 = model_sklearn.score(X_test_vec_sklearn, y_test1)\n",
    "print(\"Accuracy:\", accuracy1)\n",
    "print('Classification Report:\\n', classification_report(y_test1, y_pred1))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test1, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
